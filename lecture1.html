<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Statistics: Data analysis and modelling</title>
    <meta charset="utf-8" />
    <meta name="author" content="Maarten Speekenbrink" />
    <script src="libs/header-attrs-2.25/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="mycss.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Statistics: Data analysis and modelling
]
.subtitle[
## Week 1: Statistical models and inference
]
.author[
### Maarten Speekenbrink
]

---






## The "cookbook" approach

&lt;img src="img/test_flow_chart.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

## Model comparison approach

Building statistical models, e.g. *linear models*
`$$Y_i = \beta_0 + \beta_1 \times X_{1,i} + \beta_2 \times X_{2,i} + \ldots + \beta_m \times X_{m,i} + \epsilon_i \quad \quad \epsilon_i \sim \mathbf{Normal}(0,\sigma_\epsilon)$$`
--

Example:
`$$\texttt{achievement}_i = \beta_0 + \beta_1 \times \texttt{motivation}_i + \beta_2 \times \texttt{ability}_i + \epsilon_i \quad \quad \epsilon_i \sim \mathbf{Normal}(0,\sigma_\epsilon)$$`

Test whether motivation has an effect on achievement by comparing MODEL G above to MODEL R

`$$\texttt{achievement}_i = \beta_0 + \mathbf{0} \times \texttt{motivation}_i + \beta_2 \times \texttt{ability}_i + \epsilon_i \quad \quad \epsilon_i \sim \mathbf{Normal}(0,\sigma_\epsilon)$$`
--

A main quantity in model comparison is the likelihood-ratio:

`$$\text{likelihood-ratio} = \frac{p(\text{DATA}|\text{MODEL R})}{p(\text{DATA}|\text{MODEL G})}$$`

---

## Topics by week

1. Foundations: Data, statistical models, statistical inference
2. GLM 1 (multiple regression, moderation)
3. GLM 2 (contrast coding/ANOVA)
4. ANCOVA and linear mixed-effects models
5. Linear mixed-effects models 2
6. Generalized linear models
7. Path models (Structural Equation Models 1)
8. Latent variable models (SEM 2)
9. Bayesian estimation
10. Bayesian hypothesis testing (Bayes Factors)

---

## Module structure

The module takes a *blended learning* approach

Online:

* Textbooks
* Videos
* Quizzes
* Q &amp; A forum

In person:

* Monday introduction and Q&amp;A session
* Thursday practical

---

## Assessment

A single piece of coursework (3000 words) describing statistical analyses and results. You will be assigned a dataset to analyse, with information about the study and research questions. You can come up with additional hypotheses of interest to test.

Deadline to be confirmed (may be **8 January 2024**).

In addition to the write-up, you will also be asked to submit your analyses code (R script). This is not marked but can be helpful in case things are unclear to markers.

It is recommended to use R Markdown for the report and to start practising R Markdown in the weekly exercises. 

---

## Statistics: Data analysis and modelling

&lt;iframe width="1212" height="682" src="https://mspeekenbrink.github.io/sdam-book" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" style="width:100%; height:100%;" allowfullscreen&gt;&lt;/iframe&gt;

---

## R companion to SDAM

&lt;iframe width="1212" height="682" src="https://mspeekenbrink.github.io/sdam-r-companion" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" style="width:100%; height:100%;" allowfullscreen&gt;&lt;/iframe&gt;


---

## Preparation for Thursday practical

* Read the chapters of the SDAM and R companion books listed on Moodle
* Read the exercise sheet and complete the "Preparatory bits and pieces"
* Install `R` and `R-studio` on your laptop, and the `sdamr` package.

---

## This week

* Data, the Data Generating Process, and statistical models
* Parameter estimation by maximum likelihood
* Inference of parameters via model comparison and the likelihood ratio
* The Normal distribution and the one-sample `\(t\)`-test

---

## Data

Different types of data

* Favourite character from Star Wars (Luke Skywalker, Princess Leia Organa, Han Solo, Yoda, Darth Vader, the Emperor, etc)
* Prediction of the outcome of a football match (correct or incorrect)
* "I like statistics" (strongly disagree, disagree, neither agree nor disagree, agree, strongly agree)
* "I love statistics" (place marker on a line)
* Response-time in a motion detection task

--

Measurement scales:

*Categorical*

* Nominal
* Ordinal

*Metric*

* Interval
* Ratio
---

## What is the height of Mount Everest?

&lt;img src="lecture1_files/figure-html/unnamed-chunk-2-1.png" width="60%" style="display: block; margin: auto;" /&gt;

`\(n=109\)` Polish participants, provided with an *anchor* of 610 meters.

---

## The Data Generating Process

* Participants were recruited in-person (Polish university) or online (visitors to Polish website). Number of participants likely based on opportunity.
* Among other questions, participants were asked "Mount Everest is taller than 610 meters. How tall is Mount Everest?"

The **Data Generating Process** refers to how this data was collected, as well as *all possible replications* of the study.

--

The set of all possible replications of the study defines the **population** from which the current **sample** was drawn. The scientific interest is not in the current sample, but in the population: We want to **generalize** from sample to population.


---

## Statistical models

A statistical model defines a **probability distribution** over possible data.

Statistical models aim to capture important aspects of the **Data Generating Process**.

Most models consist of a **structural** (predictable) part, and a **random** (unpredictable) part.

Models contain **parameters** which are assumed known or otherwise can be estimated.

---

## The Normal distribution

&lt;img src="lecture1_files/figure-html/unnamed-chunk-3-1.png" width="80%" style="display: block; margin: auto;" /&gt;

--

Two parameters:
* The mean `\(\mu\)`
* The standard deviation `\(\sigma\)`

---

## Unbiased but noisy judgements?

&lt;img src="lecture1_files/figure-html/unnamed-chunk-4-1.png" width="80%" style="display: block; margin: auto;" /&gt;

Two parameters:
* `\(\underline{\mu} = 8848\)`
* The standard deviation `\(\sigma\)`

---

## A good model?

&lt;img src="lecture1_files/figure-html/unnamed-chunk-5-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

## A good model?

&lt;img src="lecture1_files/figure-html/unnamed-chunk-6-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

## Maximum likelihood estimation

Assuming independence, the **likelihood** is

`$$p(\text{DATA}|\text{MODEL}) = \prod_{i=1}^n p(Y_i|\underline{\mu} = 8848, \sigma)$$`

**Maximum likelihood estimation**: Find the value of `\(\sigma\)` such that `\(p(\text{DATA}|\text{MODEL})\)` reaches its maximum.

--

&lt;img src="lecture1_files/figure-html/unnamed-chunk-7-1.png" width="70%" style="display: block; margin: auto;" /&gt;

---

## Maximum likelihood MODEL R

&lt;img src="lecture1_files/figure-html/unnamed-chunk-8-1.png" width="80%" style="display: block; margin: auto;" /&gt;
---

## Why maximum likelihood?

When estimating a parameter from noisy data, it is unlikely we will find the true value *exactly*. 

Good estimators are

* **Unbiased**: on average (over all possible datasets) estimates are equal to the true parameter value
* **Consistent**: with larger datasets, estimates are less variable (more reliable)
* **Efficient**: variability is at the lowest bound (most reliable)

--

Maximum likelihood estimators are consistent and (asymptotically) efficient. They are not always unbiased, but the bias decreases with larger datasets. Maximum likelihood estimates are (asymptotically) Normal-distributed. 

---

## Maximum likelihood estimation MODEL G

&lt;img src="lecture1_files/figure-html/unnamed-chunk-9-1.png" width="80%" style="display: block; margin: auto;" /&gt;
Two estimated parameters

* `\(\hat{\mu} = 6312.19\)`
* `\(\hat{\sigma} = 3135.74\)`

---

## Two alternative models

&lt;img src="lecture1_files/figure-html/unnamed-chunk-10-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

## Models and decisions

Two models

* MODEL R: `\(\mu = 8848\)`, `\(\sigma\)` unknown but can be estimated
* MODEL G: both `\(\mu\)` and `\(\sigma\)` unknown but can be estimated

MODEL R is more specific and contains more information.


|                 |accept MODEL R |reject MODEL R |
|:----------------|:--------------|:--------------|
|MODEL R is true  |correct        |error (Type 1) |
|MODEL R is false |error (Type 2) |correct        |

--

We would like a decision procedure which maximises the probability of correct decisions, and minimises the probability of errors.

--

*Neyman-Pearson lemma*: For two models without unknown parameters, a test based on the likelihood-ratio minimises the probability of Type 2 errors for any given probability of Type 1 errors.

---

## Model comparison and parameter inference

Two alternative models:

* **MODEL R**: `\(\underline{\mu} = 8848\)`, `\(\hat{\sigma} = 4021.56\)`
* **MODEL G**: `\(\hat{\mu} = 6312.19\)`, `\(\hat{\sigma} = 3135.74\)`

`$$\frac{p(\text{DATA}|\text{MODEL R})}{p(\text{DATA}|\text{MODEL G})} \approx .000000000001$$`

--

With maximum likelihood estimation, it will *always* be the case that

`$$p(\text{DATA}|\text{MODEL G}) \geq p(\text{DATA}|\text{MODEL R})$$`
so
`$$\frac{p(\text{DATA}|\text{MODEL R})}{p(\text{DATA}|\text{MODEL G})} \leq 1$$`
--

Is the difference *sufficient* to reject MODEL R?

---

## Distribution of the likelihood ratio

Using MODEL R, we can simulate (noisy) datasets of `\(n=109\)` and for each compute the value of the likelihood ratio for estimated MODEL R and MODEL G based on that data. This provides a distribution of likelihood ratio values under the assumption that MODEL R is true.

&lt;img src="lecture1_files/figure-html/unnamed-chunk-12-1.png" width="80%" style="display: block; margin: auto;" /&gt;
--

A value of .000000000001 is very unlikely!

---

## `\(p\)`-value and significance

&lt;img src="lecture1_files/figure-html/unnamed-chunk-13-1.png" width="70%" style="display: block; margin: auto;" /&gt;
The `\(p\)`-value is the probability of obtaining a particular *or more extreme* value for a given test statistic (e.g. likelihood-ratio), assuming MODEL R is true.

---

## `\(p\)`-value and significance

&lt;img src="lecture1_files/figure-html/unnamed-chunk-14-1.png" width="70%" style="display: block; margin: auto;" /&gt;
The `\(p\)`-value is the probability of obtaining a particular *or more extreme* value for a given test statistic (e.g. likelihood-ratio), assuming MODEL R is true.

For a significance level `\(\alpha\)` (usually `\(\alpha = .05\)`), we can determine a *critical value* (the value of the statistic with `\(p\)`-value = `\(\alpha\)`). Rejecting models which exceed the critical value will limit the probability of Type 1 errors to at most `\(\alpha\)`.


---

## t-test

Deriving the distribution of the likelihood ratio under the assumption that MODEL R is true is generally difficult. It can be easier to work with a related statistic, in this case

`$$t = \frac{\overline{Y} - \underline{\mu}}{\hat{\sigma}/\sqrt{n}}$$`
Assuming MODEL R is true, this statistic follows a t-distribution with *degrees of freedom* `\(\text{df} = n-1\)`.

&lt;img src="lecture1_files/figure-html/unnamed-chunk-15-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

## Is there a better model?

&lt;img src="lecture1_files/figure-html/unnamed-chunk-16-1.png" width="80%" style="display: block; margin: auto;" /&gt;
A *mixture model*:

* With probability `\(p = 0.232\)` affected by the anchor `\((\hat{\mu} = 1518, \hat{\sigma} = 715)\)`
* With probability `\(p = 0.245\)` estimate "average" mountain `\((\hat{\mu} = 5994, \hat{\sigma} = 2480)\)`
* With probability `\(p = 0.523\)` (roughly) know correct answer `\((\hat{\mu} = 8583, \hat{\sigma} = 361)\)`

---

## Does it matter?

That depends...

1. As a more accurate model of the Data Generating Process: Yes!
2. To make inferences about the average judgement: Probably not...

--

.pull-left[
The **Central Limit Theorem**:

The distribution of the sum of n independent variables approaches the Normal distribution as the number of variables approaches infinity `\((n \rightarrow \infty)\)`.
]

.pull-right[
&lt;img src="lecture1_files/figure-html/unnamed-chunk-17-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]


--

In statistical tests, assumptions such as a Normal distribution matter only for the distribution of the test statistic.


---

## Summary

* Data is a random sample from the **Data Generating Process**.
* A **statistical model** aims to capture the important aspects of the Data Generating Process.
* A statistical model has **parameters** which can be assumed known or estimated.
* **Maximum likelihood estimation** is often used to estimate unknown parameters. Maximum likelihood estimates are **consistent** and (asymptotically) **efficient**, but not always **unbiased**.
* A claim about a parameter (e.g. `\(\underline{\mu} = 8848\)`) can be tested by comparing two **nested models**: MODEL R where the parameter is assumed known, and MODEL G where the parameter is not assumed known.
* A general statistic for (nested) model comparison is the **likelihood ratio**:
`$$\frac{p(\text{DATA}|\text{MODEL R})}{p(\text{DATA}|\text{MODEL G})}$$`
* **Null-hypothesis significance testing** controls the probability of **Type 1 errors**. The probability of **Type 2 errors** is usually unknown. It consists of determining the probability of a value or more extreme one under the assumption that the null-hypothesis (MODEL R) is true. This is the `\(p\)`-value.

---

## Possible points for discussion

* How can statistics help us learn about the human mind and behaviour?
* Are statistical models ever "true"?
* Why is the conventional significance level set at `\(\alpha = .05\)`?
* Why should we care about the Data Generating Process?
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
